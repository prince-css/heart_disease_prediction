# -*- coding: utf-8 -*-
"""heart_disease_prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OZMtKsHYSF7Efg8Tc3nIGjAyLL6DGoF8

### **Background**

dataset: https://archive.ics.uci.edu/ml/datasets/Heart+Disease

This database contains 76 attributes, but all published experiments refer to using a subset of 14 of them. In particular, the Cleveland database is the only one that has been used by ML researchers to
this date. The "goal" field refers to the presence of heart disease in the patient. It is integer valued from 0 (no presence) to 4. Experiments with the Cleveland database have concentrated on simply attempting to distinguish presence (values 1,2,3,4) from absence (value 0).

The names and social security numbers of the patients were recently removed from the database, replaced with dummy values.

Only 14 attributes used:
1. #3 (age)
2. #4 (sex)
3. #9 (cp):chest pain type

>>-- Value 1: typical angina

>>-- Value 2: atypical angina

>>-- Value 3: non-anginal pain

>>-- Value 4: asymptomatic

4. #10 (trestbps): resting blood pressure (in mm Hg on admission to the hospital)
5. #12 (chol):serum cholestoral in mg/dl
6. #16 (fbs):fasting blood sugar > 120 mg/dl (1 = true; 0 = false)
7. #19 (restecg):resting electrocardiographic results

>>-- Value 0: normal

>>-- Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)

>>-- Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria

8. #32 (thalach): maximum heart rate achieved
9. #38 (exang):exercise induced angina (1 = yes; 0 = no)
10. #40 (oldpeak): ST depression induced by exercise relative to rest
11. #41 (slope):the slope of the peak exercise ST segment

>>-- Value 1: upsloping

>>-- Value 2: flat

>>-- Value 3: downsloping

12. #44 (ca):number of major vessels (0-3) colored by flourosopy
13. #51 (thal): 3 = normal; 6 = fixed defect; 7 = reversable defect
14. #58 (num) (the predicted attribute)

### **Importing dependencies**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""### **Importing dataset**"""

dataset=pd.read_csv("heart.csv")
dataset.head()

dataset.info()

dataset.describe()

X=dataset.iloc[:,:-1].values
y=dataset.iloc[:,-1].values

"""### **Splitting dataset**"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.1, random_state=2)
print(X.shape, X_train.shape, X_test.shape)

from sklearn.preprocessing import StandardScaler
sc=StandardScaler()
#X_train=sc.fit_transform(X_train)

"""### **Initializing and training model**"""

from sklearn.linear_model import LogisticRegression
regressor=LogisticRegression()
regressor.fit(X_train, y_train)

"""### **Predicting by the model**"""

y_pred_train=regressor.predict(X_train)
from sklearn.metrics import accuracy_score
print("Train accuracy; ",accuracy_score(y_train, y_pred_train))

y_pred=regressor.predict(X_test)
print("Test accuracy; ",accuracy_score(y_test, y_pred))

"""### **Building a predictive system**"""

#Predicting a single value 
input_data = (62,0,0,140,268,0,0,160,0,3.6,0,2,2)
input_data=np.array(input_data)
#here input_data is a 1D nparray.but our regressor expect a 2D array.
#So, we have to reshape it from 1D to 2D
#print(input_data.shape)
input_data=input_data.reshape(1,-1)
#print(input_data.shape)
output=regressor.predict(input_data)
print(output)